{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, there are three evaluation metrics used in ranking or recommendation system which are\n",
    "1. Mean Average Precision (MAP)\n",
    "2. Precision@k\n",
    "3. Normalized Discounted Cumulative Gain  (NDCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mean Average Precision (MAP)\n",
    "According to the link https://www.youtube.com/watch?v=pM6DJ0ZZee0, Mean Average Precision (MAP) is the standard single-number measure for comparing search algorithms. Average precision (AP) is the average of (un-interpolated) precision values at all ranks where relevant documents are found. \n",
    "\n",
    "However, we need to compute AP first then average them to get MAP.\n",
    "\n",
    "The function apk is modified from https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "To get the result the same as AP, we have to define k= length of predicted list. \n",
    "\n",
    "For example, given actual=[1], predicted = [1,1,3,4,1], and k=5. The apk calculates the precision:\n",
    "i=1 p = 1/1\n",
    "i=2 p = 2/2\n",
    "i=3 rel = 0\n",
    "i=4 rel = 0\n",
    "i=5 p = 3/5\n",
    "So, apk@5 = (1 + 1 + 0.6) / 3 =  0.8666666666666667;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "    else:\n",
    "        k=len(predicted)\n",
    "        \n",
    "    predicted=np.array(predicted).astype(float).reshape(1,k)\n",
    "    y_true= np.array(actual).astype(float).reshape(len(actual),1)\n",
    "    onesmatrix=np.ones_like(predicted)\n",
    "    compare_matrix=np.dot(y_true,onesmatrix)\n",
    "    cp=1.0*(compare_matrix==predicted)\n",
    "\n",
    "    length=np.arange(1,k+1,1)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return np.sum(np.cumsum(cp)*cp/length)/np.sum(cp)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Answer=', [1], 'predicted=', [1, 1, 3, 4, 1])\n",
      "('AP@5 =', 0.8666666666666667)\n"
     ]
    }
   ],
   "source": [
    "actual = [1]\n",
    "k=5\n",
    "predicted = [1,1,3,4,1]\n",
    "print('Answer=',actual,'predicted=',predicted)\n",
    "print('AP@{} ='.format(k),apk(actual,predicted,k) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function mapk computes the mean average precision at k among lists of items.\n",
    "As mentioned before, by defining k=length of a predicted list, we get the MAP.\n",
    "\n",
    "For example, given actual=[[1],[1],[1],[1],[1]] and \n",
    "predicted=[[1,1,3,4,1],[2,1,3,4,5],[3,2,1,4,5],[4,2,3,1,5],[4,2,3,5,1]]\n",
    "For each input list:\n",
    "i=1  apk= 0.8666666666666667\n",
    "i=2  apk= 0.5\n",
    "i=3  apk= 0.3333333333333333\n",
    "i=4  apk= 0.25\n",
    "i=5  apk= 0.2\n",
    "So, mapk@5 = (0.8666666666666667 + 0.5 + 0.3333333333333 +0.25 +0.2) / 5 =  0.43;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "            \n",
    "            https://www.kaggle.com/wendykan/map-k-demo\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MAP@5 =', 0.43)\n"
     ]
    }
   ],
   "source": [
    "actual=[[1],[1],[1],[1],[1]]\n",
    "predicted=[[1,1,3,4,1],[2,1,3,4,5],[3,2,1,4,5],[4,2,3,1,5],[4,2,3,5,1]]\n",
    "print('MAP@5 =',mapk(actual, predicted, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Precision at K\n",
    "According to Evaluation Metrics for Model Selection in Ranking slide, Precision at kâ€™ is the proportion of recommended items in the top-k set that are relevant.\n",
    "Suppose that my precision at 10 in a top-10 recommendation items is 80% (0.8). This means that 8 out of 10 items that recommended are relevant to the user.\n",
    "Precision@k = (no. relevant items of k-recommended) / k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, given actual=[1], predicted = [1,1,3,4,1], and k=5. The pk calculates the precision at k:\n",
    "So, pk@5 = (1 + 1 + 0 +0 + 1) / 5 =  0.6;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the precision at k.\n",
    "    This function computes the prscision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    y_true= np.array(actual)\n",
    "    onesmatrix=np.ones_like((actual))\n",
    "    compare_matrix=np.dot(actual,onesmatrix)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return np.mean(compare_matrix == predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Answer=', [1], 'predicted=', [1, 1, 3, 4, 1])\n",
      "('PK@{} =', '5', 0.6)\n"
     ]
    }
   ],
   "source": [
    "actual = [1]\n",
    "k=5\n",
    "predicted = [1,1,3,4,1]\n",
    "print('Answer=',actual,'predicted=',predicted)\n",
    "print('PK@{} =',format(k), pk(actual,predicted,k) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Answer=', [1], 'predicted=', [1, 1, 3, 4, 1])\n",
      "('AP@5 =', 0.8666666666666667)\n",
      "('PK@5 =', 0.6)\n",
      "('Answer=', [1], 'predicted=', [2, 1, 3, 4, 5])\n",
      "('AP@5 =', 0.5)\n",
      "('PK@5 =', 0.2)\n",
      "('Answer=', [1], 'predicted=', [3, 2, 1, 4, 5])\n",
      "('AP@5 =', 0.3333333333333333)\n",
      "('PK@5 =', 0.2)\n",
      "('Answer=', [1], 'predicted=', [4, 2, 3, 1, 5])\n",
      "('AP@5 =', 0.25)\n",
      "('PK@5 =', 0.2)\n",
      "('Answer=', [1], 'predicted=', [4, 2, 3, 5, 1])\n",
      "('AP@5 =', 0.2)\n",
      "('PK@5 =', 0.2)\n"
     ]
    }
   ],
   "source": [
    "actual = [1]\n",
    "k=5\n",
    "predicted = [1,1,3,4,1]\n",
    "print('Answer=',actual,'predicted=',predicted)\n",
    "print('AP@{} ='.format(k),apk(actual,predicted,k) )\n",
    "print('PK@{} ='.format(k), pk(actual,predicted,k) )\n",
    "\n",
    "predicted = [2,1,3,4,5]\n",
    "print('Answer=',actual,'predicted=',predicted)\n",
    "print('AP@{} ='.format(k),apk(actual,predicted,k) )\n",
    "print('PK@{} ='.format(k), pk(actual,predicted,k) )\n",
    "\n",
    "predicted = [3,2,1,4,5]\n",
    "print('Answer=',actual,'predicted=',predicted)\n",
    "print('AP@{} ='.format(k),apk(actual,predicted,k) )\n",
    "print('PK@{} ='.format(k), pk(actual,predicted,k) )\n",
    "\n",
    "predicted = [4,2,3,1,5]\n",
    "print('Answer=',actual,'predicted=',predicted)\n",
    "print('AP@{} ='.format(k),apk(actual,predicted,k) )\n",
    "print('PK@{} ='.format(k), pk(actual,predicted,k) )\n",
    "\n",
    "predicted = [4,2,3,5,1]\n",
    "print('Answer=',actual,'predicted=',predicted)\n",
    "print('AP@{} ='.format(k),apk(actual,predicted,k) )\n",
    "print('PK@{} ='.format(k), pk(actual,predicted,k) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean precision at k.\n",
    "    This function computes the mean precision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns: The average precision at k over the input lists\n",
    "            \n",
    "            https://www.kaggle.com/wendykan/map-k-demo\n",
    "    \"\"\"\n",
    "    return np.mean([pk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MAP@5 =', 0.43)\n",
      "('MP@5 =', 0.27999999999999997)\n"
     ]
    }
   ],
   "source": [
    "actual=[[1],[1],[1],[1],[1]]\n",
    "predicted=[[1,1,3,4,1],[2,1,3,4,5],[3,2,1,4,5],[4,2,3,1,5],[4,2,3,5,1]]\n",
    "print('MAP@5 =',mapk(actual, predicted, k=5))\n",
    "print('MP@5 =',mpk(actual, predicted, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Normalized Discounted Cumulative Gain  (NDCG)\n",
    "\n",
    "The dcg function is modified from https://github.com/ChenglongChen/tensorflow-LTR/blob/master/src/metrics.py\n",
    "According to wiki https://en.wikipedia.org/wiki/Discounted_cumulative_gain, \n",
    "Discounted cumulative gain (DCG) is a measure of ranking quality. In information retrieval, it is often used to measure effectiveness of web search engine algorithms or related applications.\n",
    "\n",
    "The NDCG is calculated as follows\n",
    "NDCG=DCG(predicted order)/DCG(sorted predicted order)\n",
    "DCG(order)=sum(DCGi) i in order\n",
    "DCGi=orderi/(ln2(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(predicted_order):\n",
    "    \"\"\" Parameters: list predicted order\n",
    "        Output: DCG\n",
    "    \"\"\"\n",
    "    i = np.log2(1. + np.arange(1,len(predicted_order)+1))\n",
    "    l = np.array(predicted_order)\n",
    "    return np.sum(l/i)\n",
    "\n",
    "\n",
    "def ndcg(score, top_ten=True):\n",
    "    \"\"\" Parameters: list predicted order\n",
    "        Output: nDCG=DCG(predicted order)/DCG(sorted predicted order)\n",
    "    \"\"\"\n",
    "    end = 10 if top_ten else len(score)\n",
    "    sorted_score = np.sort(score)[::-1]\n",
    "    dcg_ = dcg(score[:end])\n",
    "    if dcg_ == 0:\n",
    "        return 0\n",
    "    dcg_max = dcg(sorted_score[:end])\n",
    "    return dcg_/dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.492056442164959\n",
      "0.935908621453514\n"
     ]
    }
   ],
   "source": [
    "predicted_order_ =[3,2,3,0,1,2,3,2]\n",
    "print(dcg(predicted_order_))\n",
    "print((ndcg(predicted_order_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
